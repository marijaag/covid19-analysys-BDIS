{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem koji rešavamo\n",
    "\n",
    "Zadatak se formuliše kao problem binarne klasifikacije. Cilj analize je da se na osnovu demografskih i kliničkih karakteristika pacijenata predvidi verovatnoću hospitalizacije COVID-19 pacijenata.\n",
    "\n",
    "Pravovremena procena potrebe za hospitalizacijom može pomoći zdravstvenim ustanovama u planiranju kapaciteta i efikasnijem upravljanju resursima.\n",
    "\n",
    "Ciljna promenljiva je **HOSPITALIZED**, gde vrednost 1 označava hospitalizovanog pacijenta, dok vrednost 0 označava pacijenta koji nije hospitalizovan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkML modelovanje – predikcija hospitalizacije\n",
    "\n",
    "Cilj ovog dela analize je izgradnja modela mašinskog učenja koji može da predvidi da li će COVID-19 pacijent biti hospitalizovan na osnovu demografskih i kliničkih karakteristika.  \n",
    "Model se implementira korišćenjem SparkML biblioteke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.1.1\n",
      "Master: local[*]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"COVID-SparkML-Hospitalization\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"Spark version:\", spark.version)\n",
    "print(\"Master:\", spark.sparkContext.master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Učitavanje podataka u Spark\n",
    "\n",
    "U ovom koraku učitavamo prethodno pripremljen dataset u Spark DataFrame koji će se koristiti za dalju ML analizu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- USMER: integer (nullable = true)\n",
      " |-- MEDICAL_UNIT: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- PATIENT_TYPE: integer (nullable = true)\n",
      " |-- DATE_DIED: string (nullable = true)\n",
      " |-- INTUBED: integer (nullable = true)\n",
      " |-- PNEUMONIA: integer (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- PREGNANT: integer (nullable = true)\n",
      " |-- DIABETES: integer (nullable = true)\n",
      " |-- COPD: integer (nullable = true)\n",
      " |-- ASTHMA: integer (nullable = true)\n",
      " |-- INMSUPR: integer (nullable = true)\n",
      " |-- HIPERTENSION: integer (nullable = true)\n",
      " |-- OTHER_DISEASE: integer (nullable = true)\n",
      " |-- CARDIOVASCULAR: integer (nullable = true)\n",
      " |-- OBESITY: integer (nullable = true)\n",
      " |-- RENAL_CHRONIC: integer (nullable = true)\n",
      " |-- TOBACCO: integer (nullable = true)\n",
      " |-- CLASIFFICATION_FINAL: integer (nullable = true)\n",
      " |-- ICU: integer (nullable = true)\n",
      "\n",
      "+-----+------------+---+------------+----------+-------+---------+---+--------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+--------------------+---+\n",
      "|USMER|MEDICAL_UNIT|SEX|PATIENT_TYPE| DATE_DIED|INTUBED|PNEUMONIA|AGE|PREGNANT|DIABETES|COPD|ASTHMA|INMSUPR|HIPERTENSION|OTHER_DISEASE|CARDIOVASCULAR|OBESITY|RENAL_CHRONIC|TOBACCO|CLASIFFICATION_FINAL|ICU|\n",
      "+-----+------------+---+------------+----------+-------+---------+---+--------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+--------------------+---+\n",
      "|    2|           1|  1|           1|03/05/2020|     97|        1| 65|       2|       2|   2|     2|      2|           1|            2|             2|      2|            2|      2|                   3| 97|\n",
      "|    2|           1|  2|           1|03/06/2020|     97|        1| 72|      97|       2|   2|     2|      2|           1|            2|             2|      1|            1|      2|                   5| 97|\n",
      "|    2|           1|  2|           2|09/06/2020|      1|        2| 55|      97|       1|   2|     2|      2|           2|            2|             2|      2|            2|      2|                   3|  2|\n",
      "|    2|           1|  1|           1|12/06/2020|     97|        2| 53|       2|       2|   2|     2|      2|           2|            2|             2|      2|            2|      2|                   7| 97|\n",
      "|    2|           1|  2|           1|21/06/2020|     97|        2| 68|      97|       1|   2|     2|      2|           1|            2|             2|      2|            2|      2|                   3| 97|\n",
      "+-----+------------+---+------------+----------+-------+---------+---+--------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+--------------------+---+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "spark_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv('../data/Covid Data.csv')\n",
    ")\n",
    "\n",
    "spark_df.printSchema()\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kreiranje ciljne promenljive\n",
    "\n",
    "Originalni dataset ne sadrži eksplicitnu binarnu kolonu hospitalizacije. Zbog toga se ciljna promenljiva **HOSPITALIZED** konstruiše na osnovu kolone **PATIENT_TYPE**.\n",
    "\n",
    "Vrednost 2 u koloni PATIENT_TYPE označava hospitalizovane pacijente, dok vrednost 1 označava ambulantne pacijente. Ova transformacija omogućava primenu binarne klasifikacije u SparkML okruženju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|PATIENT_TYPE|HOSPITALIZED|\n",
      "+------------+------------+\n",
      "|           1|           0|\n",
      "|           1|           0|\n",
      "|           2|           1|\n",
      "|           1|           0|\n",
      "|           1|           0|\n",
      "+------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Kreiramo labelu HOSPITALIZED iz PATIENT_TYPE\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"HOSPITALIZED\",\n",
    "    F.when(F.col(\"PATIENT_TYPE\") == 2, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "spark_df.select(\"PATIENT_TYPE\", \"HOSPITALIZED\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Izbor karakteristika i priprema podataka\n",
    "\n",
    "Za modelovanje se koriste demografske i kliničke karakteristike pacijenata.\n",
    "\n",
    "U ovoj fazi vrši se selekcija atributa i uklanjanje nedostajućih vrednosti kako bi se obezbedio kvalitet ulaznih podataka za model mašinskog učenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|HOSPITALIZED| count|\n",
      "+------------+------+\n",
      "|           1|200031|\n",
      "|           0|848544|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"AGE\",\n",
    "    \"SEX\",\n",
    "    \"PNEUMONIA\",\n",
    "    \"DIABETES\",\n",
    "    \"HIPERTENSION\",\n",
    "    \"OBESITY\",\n",
    "    \"RENAL_CHRONIC\",\n",
    "    \"COPD\"\n",
    "]\n",
    "\n",
    "label_col = \"HOSPITALIZED\"\n",
    "\n",
    "ml_df = (\n",
    "    spark_df\n",
    "    .select(features + [label_col])\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "ml_df.groupBy(label_col).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podela na trening i test skup\n",
    "\n",
    "Skup podataka deli se na trening (80%) i test (20%) deo. Model se trenira na trening skupu, dok se test skup koristi za objektivnu procenu performansi na neviđenim podacima.\n",
    "\n",
    "Ovakav pristup smanjuje rizik od preprilagođavanja (overfitting) modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 838937\n",
      "Test size: 209638\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = ml_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Train size:\", train_df.count())\n",
    "print(\"Test size:\", test_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kreiranje ML pipeline-a\n",
    "\n",
    "U cilju standardizacije procesa modelovanja koristi se SparkML pipeline. Numeričke karakteristike objedinjene su pomoću **VectorAssembler** transformacije u jedinstveni vektor obeležja.\n",
    "\n",
    "Nad tako pripremljenim podacima trenira se model logističke regresije, koji je pogodan za probleme binarne klasifikacije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=features,\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=label_col,\n",
    "    maxIter=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predikcije modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------------------------------+\n",
      "|HOSPITALIZED|prediction|probability                             |\n",
      "+------------+----------+----------------------------------------+\n",
      "|0           |0.0       |[0.981610889204295,0.018389110795705044]|\n",
      "|1           |0.0       |[0.981610889204295,0.018389110795705044]|\n",
      "|1           |0.0       |[0.981610889204295,0.018389110795705044]|\n",
      "|1           |0.0       |[0.981610889204295,0.018389110795705044]|\n",
      "|1           |0.0       |[0.981610889204295,0.018389110795705044]|\n",
      "|1           |0.0       |[0.981610889204295,0.018389110795705044]|\n",
      "|1           |0.0       |[0.981610889204295,0.018389110795705044]|\n",
      "|0           |0.0       |[0.981440909882848,0.018559090117151955]|\n",
      "|0           |0.0       |[0.981440909882848,0.018559090117151955]|\n",
      "|0           |0.0       |[0.981440909882848,0.018559090117151955]|\n",
      "+------------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(test_df)\n",
    "\n",
    "pred.select(\n",
    "    label_col,\n",
    "    \"prediction\",\n",
    "    \"probability\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacija modela\n",
    "\n",
    "Performanse modela procenjuju se korišćenjem više metrika. AUC (Area Under ROC Curve) meri sposobnost modela da razlikuje klase, dok accuracy predstavlja procenat tačno klasifikovanih primera.\n",
    "\n",
    "Dodatno, konfuziona matrica pruža uvid u tipove grešaka koje model pravi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7374\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=label_col,\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "auc = evaluator_auc.evaluate(pred)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8188\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=label_col,\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = acc_eval.evaluate(pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+\n",
      "|HOSPITALIZED|prediction| count|\n",
      "+------------+----------+------+\n",
      "|           0|       0.0|166304|\n",
      "|           0|       1.0|  3100|\n",
      "|           1|       0.0| 34879|\n",
      "|           1|       1.0|  5355|\n",
      "+------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.groupBy(label_col, \"prediction\") \\\n",
    "    .count() \\\n",
    "    .orderBy(label_col, \"prediction\") \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
